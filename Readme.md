# Supporting Material S1: Example analysis of a dataset with two factors
using prolfquapp


## Example analysis using prolfquapp

*prolfquapp* \[<https://github.com/prolfqua/prolfquapp>\] is an R
package which can be used to perform differential expression analysis of
proteins. It builds upon the core functionalities of the $prolfqua$
package \[<https://github.com/fgcz/prolfqua>\].

The data used in this analysis we sourced from [MassIVE Reanalysis -
RMSV000000696.1](https://massive.ucsd.edu/ProteoSAFe/reanalysis.jsp?task=b88e6fe3f3564773be62eefde7122127).
Two key files `report.tsv` and `msstats.tsv` were processed for this
study, each approximately 17GB in size. These files were produced from
the raw files using the FragPipe DIA workflow
<https://fragpipe.nesvilab.org/docs/tutorial_DIA.html>, and the
preprocessing is discussed in more detail in the publication by D.Kohler
et al.Â <https://doi.org/10.1038/s41596-024-01000-3>.

The dataset has $187$ samples and for more information about the
dataset, we refer you to <https://pdc.cancer.gov/pdc/study/PDC000200>.
The FragPipe DIA workflow identified and quantified $8613$ Proteins.

We have chosen this dataset is to demonstrate the performance and
functionality of the $prolfquapp$ package to analyse large datasets and
experiments with factorial designs.

# Replicating the document

The web-resource
<https://fgcz-proteomics.uzh.ch/public/wew_prolfquapp/DEA_large_example/>
contains copies of the input `report.tsv` file and `msstats.tsv` file,
and examples of `.yml` files and annotation XLSX files which the
$prolfquapp$ application requires as input. It also contains the outputs
generated by $prolfquapp$.

To recreate the analysis on your computer you will need the docker
application. Furthermore, you must download the`p_docker.sh` file. This
file is used to set up the docker container and run the analysis using
the $prolfquapp$ installation provided by the docker image.

By executing `./prolfquapp_dockers.sh quarto render Readme.qmd` you will
execute all the code blocks in this document. The folders starting with
`FragPipe_` contain the quantification results. Folders starting with
`QC_` contain the output of the `prolfqua_qc` application while folders
starting with `DEA_` contain the output of the `prolfqua_dea`
application.

## Creating a Subset of 20 files

Using the R code below we created a subset containing data only from
$20$ samples out of the $187$ samples.

``` r
library(readr)
alld <- readr::read_csv("FragPipe_all/msstats.csv")

Runs <- unique(alld$Run)
Runs20 <- sample(Runs , 20)
ms20 <- alld[alld$Run %in% Runs20,]
readr::write_csv(ms20, file = "FragPipe_f20/msstats20.csv")
```

``` r
alldiann <- readr::read_tsv("FragPipe_all_diann/report.tsv")
head(alldiann)
Runs <- alldiann$File.Name |> unique()
Runs20 <- sample(Runs , 20)

ms20diann <- alldiann[alldiann$File.Name %in% Runs20,]
readr::write_tsv(ms20diann, file = "FragPipe_f20_diann/report20.tsv")
```

We here define a helper function to compute the run-time and memmory
usage of the QC and DEA analysis.

``` r
#! label computeruntime.
runtime_DEA <- function(log_file) {
  datafLOG <- read.table(log_file, header = TRUE, sep = "", fill = TRUE,
                            comment.char = "", check.names = FALSE,
                            skip = 0)
  datafLOG <- datafLOG[!grepl("^%CPU", datafLOG$`%CPU`), ]
  datafLOG <- datafLOG[-nrow(datafLOG),]
  datafLOG$TIME  <- as.numeric(lubridate::hms(datafLOG$TIME))
  datafLOG$GB <- as.numeric(datafLOG$RSS)/(1024*1024)
  res <- list(data = datafLOG, maxGB = max(datafLOG$GB), maxTime = max(datafLOG$TIME) / 60)
  return(res)
}
```

## Setup

We start by cleaning the outputs of previous runs.

Next we deploy the shell scripts provided by the $prolfquapp$ package.

``` bash
R --vanilla -e "prolfquapp::copy_shell_script(workdir = '.')"
```

## Running prolfquapp starting from the DIANN reports.tsv file for 20 samples

Create dataset annotation file using information in the `mstats.tsv`
file.

``` bash
./prolfqua_dataset.sh -s DIANN -i FragPipe_f20_diann -d FragPipe_f20_diann/dataset_diann_example.xlsx
```

Create QC and sample size estimation report, and generate XLSX file with
protein abundance estimates using Tukeys median polish and iBAQ values.
The outputs are stored in the `qc_dir_f20_diann` folder.

``` bash
./prolfqua_qc.sh -s DIANN -i FragPipe_f20_diann -d dataset_all_parallel.xlsx -o qc_dir_f20_diann
```

### Example of parallel group design, with missingness modelling

``` bash
./prolfqua_dea.sh -s DIANN -i FragPipe_f20_diann -d dataset_all_parallel.xlsx -y config_model_missing_vsn.yml -w f20_diann_with_subject
```

### Example of factorial design, and no missingness modelling

``` bash
./prolfqua_dea.sh -s DIANN -i FragPipe_f20_diann -d dataset_all_interaction_no_Subject.xlsx -y config_vsn.yml -w f20_diann_with_interaction
```

### Example PEPTIDE level analysis

Note that we use the `DIANN_PEPTIDE` option here.

``` bash
./prolfqua_dea.sh -s DIANN_PEPTIDE -i FragPipe_f20_diann -d dataset_all_parallel.xlsx -y config_model_missing_vsn.yml -w f20_diann_peptide_with_subject
```

``` r
undebug(runtime_DEA)
resDS <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dataset.log")
resQ <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_qc.log")
resD1 <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dea_2.log")
resD2 <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dea_1.log")
resDPEP <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dea.log")

timing <- data.frame(name = c("Dataset", "QC", "DEA1", "DEA2","DEAPEP"),
  RAM_GB = c(resDS$maxGB, resQ$maxGB, resD1$maxGB , resD2$maxGB, resDPEP$maxGB),
  Time = c(resDS$maxTime, resQ$maxTime, resD1$maxTime , resD2$maxTime, resDPEP$maxTime))

knitr::kable(timing,caption = "f20 DIANN report tsv input")
```

| name    |    RAM_GB |      Time |
|:--------|----------:|----------:|
| Dataset |  4.218994 |  1.633333 |
| QC      |  4.984684 |  7.100000 |
| DEA1    |  5.067066 | 14.066667 |
| DEA2    |  5.109268 | 12.366667 |
| DEAPEP  | 21.376057 | 90.716667 |

f20 DIANN report tsv input

## Running starting from the DIANN reports.tsv file for 187 samples

The code is identical with the code above except that we specify that
the output is a DIANN file by setting `-s DIANN` instead of
`-s MSSTATS_FP_DIA`.

``` bash
./prolfqua_dataset.sh -s DIANN -i FragPipe_f187_diann -d FragPipe_f187_diann/dataset_diann_example.xlsx
```

``` bash
./prolfqua_qc.sh -s DIANN -i FragPipe_f187_diann -d dataset_all_parallel.xlsx -o qc_dir_f187_diann
```

``` bash
./prolfqua_dea.sh -s DIANN -i FragPipe_f187_diann -d dataset_all_interaction_no_Subject.xlsx -y config_vsn.yml -w f187_diann_with_interaction
```

``` r
undebug(runtime_DEA)
resDS <- runtime_DEA("FragPipe_f187_diann/prolfqua_logMemUsage_dataset.log")
resQ <- runtime_DEA("FragPipe_f187_diann/prolfqua_logMemUsage_qc.log")
# resD1 <- runtime_DEA("FragPipe_f187_diann/prolfqua_logMemUsage_dea_1.log")
resD2 <- runtime_DEA("FragPipe_f187_diann/prolfqua_logMemUsage_dea.log")

timing <- data.frame(name = c("Dataset", "QC", "DEA1"),
  RAM_GB = c(resDS$maxGB, resQ$maxGB,resD2$maxGB),
  Time = c(resDS$maxTime, resQ$maxTime, resD2$maxTime))

knitr::kable(timing,caption = "f187 DIANN report tsv input")
```

| name    |   RAM_GB |     Time |
|:--------|---------:|---------:|
| Dataset | 36.25261 | 11.40000 |
| QC      | 40.07573 | 41.68333 |
| DEA1    | 38.54958 | 50.63333 |

f187 DIANN report tsv input

## Running analysis for MSstats output for the small dataset with 20 files.

$FragPipe$ can reformat the $DIA-NN$ output in report.tsv to $MSstats$
compatible output. We show here that you can run a similar analysis
starting from this output using prolfqua.

Create dataset annotation file using information in the `mstats.tsv`
file.

``` bash
./prolfqua_dataset.sh -s MSSTATS -i FragPipe_f20_msstats -d FragPipe_f20_msstats/dataset_msstats20_example.xlsx
./prolfqua_qc.sh -s MSSTATS_FP_DIA -i FragPipe_f20_msstats -d dataset_all_parallel.xlsx -o qc_dir_msstats20
```

``` bash
./prolfqua_dea.sh -s MSSTATS_FP_DIA -i FragPipe_f20_msstats -d dataset_all_parallel.xlsx -y config_model_missing_vsn.yml -w f20_msstats_parallel_with_subject
./prolfqua_dea.sh -s MSSTATS_FP_DIA -i FragPipe_f20_msstats -d dataset_all_interaction_no_Subject.xlsx -y config_vsn.yml -w f20_msstats_with_interaction_no_subject
```

``` r
undebug(runtime_DEA)
resDS <- runtime_DEA("FragPipe_f20_msstats/prolfqua_logMemUsage_dataset.log")
resQ <- runtime_DEA("FragPipe_f20_msstats/prolfqua_logMemUsage_qc.log")
resD1 <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dea_1.log")
resD2 <- runtime_DEA("FragPipe_f20_diann/prolfqua_logMemUsage_dea.log")

timing <- data.frame(name = c("Dataset", "QC", "DEA1", "DEA2"),
  RAM_GB = c(resDS$maxGB, resQ$maxGB, resD1$maxGB , resD2$maxGB),
  Time = c(resDS$maxTime, resQ$maxTime, resD1$maxTime , resD2$maxTime))

knitr::kable(timing,caption = "f20 MSstats csv input")
```

| name    |    RAM_GB |     Time |
|:--------|----------:|---------:|
| Dataset |  4.316433 |  2.10000 |
| QC      |  4.314503 |  6.30000 |
| DEA1    |  5.109268 | 12.36667 |
| DEA2    | 21.376057 | 90.71667 |

f20 MSstats csv input

# R version and session information

``` r
pander::pander(sessionInfo())
```
